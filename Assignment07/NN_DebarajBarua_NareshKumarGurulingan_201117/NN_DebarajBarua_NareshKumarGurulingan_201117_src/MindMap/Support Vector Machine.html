<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><!--This file has been created with freemind2html.xsl--><head><title>Support Vector Machine</title><link rel="stylesheet" href="Support Vector Machine.html_files/freemind2html.css" type="text/css"/><meta name="generator" content="FreeMind-XSL Stylesheet (see: http://freemind-xsl.dev.slash-me.net/ for details)"/><script type="text/javascript" src="Support Vector Machine.html_files/freemind2html.js">  
	</script><script type="text/javascript"><!--
          
               function toggle(id)
               {
                   div_el = document.getElementById(id);
                   img_el = document.getElementById('img'+id);
                   if (div_el.style.display != 'none')
                   {
          
					
                      div_el.style.display='none';
                      img_el.src = 'Support Vector Machine.html_files/show.png';
          
                   }
                   else
                   {
          
                      div_el.style.display='block';
                      img_el.src = 'Support Vector Machine.html_files/hide.png';
          
                   };
               };
          
          --></script></head><body><h1>Support Vector Machine</h1><div style="width:96%;  padding:2%;  margin-bottom:10px;  border: 0px;  text-align:center;  vertical-align:center;"><img src="Support Vector Machine.html_files/image.png" style="margin-bottom:10px; &#9;border: 0px; &#9;text-align:center; &#9;vertical-align:center;" alt="Imagemap" usemap="#fm_imagemap"/></div><map name="fm_imagemap" id="fm_imagemap"><area shape="rect" href="#FMID_1196709283FM" alt="Support Vector Machine" title="Support Vector Machine" coords="894,165,1073,203" /><area shape="rect" href="#FMID_588709879FM" alt="Optimal Hyperplane for Linearly Separabl ..." title="Optimal Hyperplane for Linearly Separabl ..." coords="958,69,1290,88" /><area shape="rect" href="#FMID_1802638467FM" alt="Quadratic Optimization for finding the o ..." title="Quadratic Optimization for finding the o ..." coords="1312,49,1681,68" /><area shape="rect" href="#FMID_929237358FM" alt="Characterized as" title="Characterized as" coords="1700,22,1817,41" /><area shape="rect" href="#FMID_665910343FM" alt="Cost function is a convex function of w" title="Cost function is a convex function of w" coords="1837,11,2089,30" /><area shape="rect" href="#FMID_285488417FM" alt="Constraints are linear in w" title="Constraints are linear in w" coords="1837,33,2013,52" /><area shape="rect" href="#FMID_28600710FM" alt="Solve via the method of Lagrange multipl ..." title="Solve via the method of Lagrange multipl ..." coords="1701,71,1991,90" /><area shape="rect" href="#FMID_1160405002FM" alt="Statistical Properties of the Optimal Hy ..." title="Statistical Properties of the Optimal Hy ..." coords="1310,102,1620,121" /><area shape="rect" href="#FMID_1378067777FM" alt="Optimal Hyperplanes for Non-separable pa ..." title="Optimal Hyperplanes for Non-separable pa ..." coords="954,245,1290,265" /><area shape="rect" href="#FMID_427981739FM" alt="Margin of Separation" title="Margin of Separation" coords="1324,201,1467,220" /><area shape="rect" href="#FMID_427666275FM" alt="Parameter C" title="Parameter C" coords="1310,257,1400,276" /><area shape="rect" href="#FMID_524094451FM" alt="Determined experimentally via the standa ..." title="Determined experimentally via the standa ..." coords="1420,239,1866,258" /><area shape="rect" href="#FMID_620881054FM" alt="Or, Determined  analytically by estimati ..." title="Or, Determined  analytically by estimati ..." coords="1419,299,2031,333" /><area shape="rect" href="#FMID_640656922FM" alt="Building SVM for pattern Recgonition" title="Building SVM for pattern Recgonition" coords="648,45,889,64" /><area shape="rect" href="#FMID_1908355134FM" alt="Inner-Product Kernel" title="Inner-Product Kernel" coords="488,0,628,19" /><area shape="rect" href="#FMID_2554366FM" alt="Mercer's Theorem" title="Mercer's Theorem" coords="504,22,628,41" /><area shape="rect" href="#FMID_390598872FM" alt="Optimum Design of a suppoer Vector Machi ..." title="Optimum Design of a suppoer Vector Machi ..." coords="329,44,628,63" /><area shape="rect" href="#FMID_1274590669FM" alt="Summary" title="Summary" coords="559,78,628,97" /><area shape="rect" href="#FMID_199650307FM" alt="Conceptual Problem" title="Conceptual Problem" coords="381,66,539,86" /><area shape="rect" href="#FMID_166337187FM" alt="Computational Problem" title="Computational Problem" coords="361,89,539,109" /><area shape="rect" href="#FMID_1565896074FM" alt="Computer Experiment" title="Computer Experiment" coords="701,133,848,152" /><area shape="rect" href="#FMID_239041166FM" alt="Summarizing Remarks" title="Summarizing Remarks" coords="533,131,681,150" /><area shape="rect" href="#FMID_1355889127FM" alt="SVM has the inherent ability to optimall ..." title="SVM has the inherent ability to optimall ..." coords="0,120,513,140" /><area shape="rect" href="#FMID_450952557FM" alt="MLP with back-propagation, provides comp ..." title="MLP with back-propagation, provides comp ..." coords="61,143,513,162" /><area shape="rect" href="#FMID_1398012094FM" alt="Error Insensitive Loss Function" title="Error Insensitive Loss Function" coords="652,208,855,227" /><area shape="rect" href="#FMID_1963795568FM" alt="SVM for Non-linear Regression" title="SVM for Non-linear Regression" coords="680,291,881,310" /><area shape="rect" href="#FMID_190591826FM" alt="Problems" title="Problems" coords="590,289,660,308" /><area shape="rect" href="#FMID_1243335793FM" alt="Parameters E and C must be tuned simulta ..." title="Parameters E and C must be tuned simulta ..." coords="240,278,570,297" /><area shape="rect" href="#FMID_1100362415FM" alt="Regression is intrinsically more difficu ..." title="Regression is intrinsically more difficu ..." coords="144,300,570,319" /></map>

<div class="node"><img src="Support Vector Machine.html_files/hide.png" class="hideshow" alt="hide" onClick="toggle(&quot;N65543&quot;)" id="imgN65543"/><a id="FMID_1196709283FM"/><div class="nodecontent">Support Vector Machine</div><div class="content" id="N65543"><div class="node"><img src="Support Vector Machine.html_files/hide.png" class="hideshow" alt="hide" onClick="toggle(&quot;N65549&quot;)" id="imgN65549"/><a id="FMID_588709879FM"/><div class="nodecontent">Optimal Hyperplane for Linearly Separable Patterns</div><div class="content" id="N65549"><div class="node"><img src="Support Vector Machine.html_files/hide.png" class="hideshow" alt="hide" onClick="toggle(&quot;N65558&quot;)" id="imgN65558"/><a id="FMID_1802638467FM"/><div class="nodecontent">Quadratic Optimization for finding the optimal hyperplane</div><div class="content" id="N65558"><div class="node"><img src="Support Vector Machine.html_files/hide.png" class="hideshow" alt="hide" onClick="toggle(&quot;N65566&quot;)" id="imgN65566"/><a id="FMID_929237358FM"/><div class="nodecontent">Characterized as</div><div class="content" id="N65566"><div class="node"><img src="Support Vector Machine.html_files/leaf.png" class="hideshow" alt="leaf"/><a id="FMID_665910343FM"/><div class="nodecontent">Cost function is a convex function of w</div></div><div class="node"><img src="Support Vector Machine.html_files/leaf.png" class="hideshow" alt="leaf"/><a id="FMID_285488417FM"/><div class="nodecontent">Constraints are linear in w</div></div></div></div><div class="node"><img src="Support Vector Machine.html_files/leaf.png" class="hideshow" alt="leaf"/><a id="FMID_28600710FM"/><div class="nodecontent">Solve via the method of Lagrange multipliers</div></div></div></div><div class="node"><img src="Support Vector Machine.html_files/leaf.png" class="hideshow" alt="leaf"/><a id="FMID_1160405002FM"/><div class="nodecontent">Statistical Properties of the Optimal Hyperplane</div></div></div></div><div class="node"><img src="Support Vector Machine.html_files/hide.png" class="hideshow" alt="hide" onClick="toggle(&quot;N65601&quot;)" id="imgN65601"/><a id="FMID_1378067777FM"/><div class="nodecontent">Optimal Hyperplanes for Non-separable patterns</div><div class="note-and-attributes"><span class="note">
    <ul>
      <li>
         Nonconvex optimization problem, So np-complete
      </li>
      <li>
         Approximating the minimization function, we get the parameter C
      </li>
    </ul>
  </span></div><div class="content" id="N65601"><div class="node"><img src="Support Vector Machine.html_files/leaf.png" class="hideshow" alt="leaf"/><a id="FMID_427981739FM"/><div class="nodecontent">Margin of Separation</div></div><div class="node"><img src="Support Vector Machine.html_files/hide.png" class="hideshow" alt="hide" onClick="toggle(&quot;N65638&quot;)" id="imgN65638"/><a id="FMID_427666275FM"/><div class="nodecontent">Parameter C</div><div class="content" id="N65638"><div class="node"><img src="Support Vector Machine.html_files/leaf.png" class="hideshow" alt="leaf"/><a id="FMID_524094451FM"/><div class="nodecontent">Determined experimentally via the standard use of a training test set</div></div><div class="node"><img src="Support Vector Machine.html_files/leaf.png" class="hideshow" alt="leaf"/><a id="FMID_620881054FM"/><div class="nodecontent">Or, Determined  analytically by estimating the VC dimension and then by using bounds on the generalization perfirmance of the machine based on the VC dimension</div></div></div></div></div></div><div class="node"><img src="Support Vector Machine.html_files/hide.png" class="hideshow" alt="hide" onClick="toggle(&quot;N65660&quot;)" id="imgN65660"/><a id="FMID_640656922FM"/><div class="nodecontent">Building SVM for pattern Recgonition</div><div class="content" id="N65660"><div class="node"><img src="Support Vector Machine.html_files/leaf.png" class="hideshow" alt="leaf"/><a id="FMID_1908355134FM"/><div class="nodecontent">Inner-Product Kernel</div></div><div class="node"><img src="Support Vector Machine.html_files/leaf.png" class="hideshow" alt="leaf"/><a id="FMID_2554366FM"/><div class="nodecontent">Mercer's Theorem</div></div><div class="node"><img src="Support Vector Machine.html_files/leaf.png" class="hideshow" alt="leaf"/><a id="FMID_390598872FM"/><div class="nodecontent">Optimum Design of a suppoer Vector Machine</div></div><div class="node"><img src="Support Vector Machine.html_files/hide.png" class="hideshow" alt="hide" onClick="toggle(&quot;N65687&quot;)" id="imgN65687"/><a id="FMID_1274590669FM"/><div class="nodecontent">Summary</div><div class="content" id="N65687"><div class="node"><img src="Support Vector Machine.html_files/leaf.png" class="hideshow" alt="leaf"/><a id="FMID_199650307FM"/><div class="nodecontent">Conceptual Problem</div><div class="note-and-attributes"><span class="note">
    <p>
      Dimensionality of the feature (hidden) space is purposefully made very large to enable the construction of a decision surface in the form of a hyperplane in that space. For good generalization performance, the model complexity is controlled by imposing certain constraints on the construction of the separating hyperplane, which reults in the extraction of a fraction of the training data as support vectors.
    </p>
  </span></div></div><div class="node"><img src="Support Vector Machine.html_files/leaf.png" class="hideshow" alt="leaf"/><a id="FMID_166337187FM"/><div class="nodecontent">Computational Problem</div><div class="note-and-attributes"><span class="note">
    <p>
       Numerical optimization in a high dimensional space suffers from the curse of dimensionality. This computational problem is avoided by using the notion of an inner product kernal (defined in accordance with Mercer's theorem) and solving the dual form of the constraineid optimization problem formulate in the input (data) space
    </p>
  </span></div></div></div></div></div></div><div class="node"><img src="Support Vector Machine.html_files/hide.png" class="hideshow" alt="hide" onClick="toggle(&quot;N65737&quot;)" id="imgN65737"/><a id="FMID_1565896074FM"/><div class="nodecontent">Computer Experiment</div><div class="content" id="N65737"><div class="node"><img src="Support Vector Machine.html_files/hide.png" class="hideshow" alt="hide" onClick="toggle(&quot;N65746&quot;)" id="imgN65746"/><a id="FMID_239041166FM"/><div class="nodecontent">Summarizing Remarks</div><div class="content" id="N65746"><div class="node"><img src="Support Vector Machine.html_files/leaf.png" class="hideshow" alt="leaf"/><a id="FMID_1355889127FM"/><div class="nodecontent">SVM has the inherent ability to optimally solve pattern classiification problem</div><div class="note-and-attributes"><span class="note">
    <ul>
      <li>
         Close to optimum mnnaer
      </li>
      <li>
         Without any problem domain knowledge built into the design of the machine
      </li>
    </ul>
  </span></div></div><div class="node"><img src="Support Vector Machine.html_files/leaf.png" class="hideshow" alt="leaf"/><a id="FMID_450952557FM"/><div class="nodecontent">MLP with back-propagation, provides computationally efficient solution</div></div></div></div></div></div><div class="node"><img src="Support Vector Machine.html_files/leaf.png" class="hideshow" alt="leaf"/><a id="FMID_1398012094FM"/><div class="nodecontent">Error Insensitive Loss Function</div></div><div class="node"><img src="Support Vector Machine.html_files/hide.png" class="hideshow" alt="hide" onClick="toggle(&quot;N65796&quot;)" id="imgN65796"/><a id="FMID_1963795568FM"/><div class="nodecontent">SVM for Non-linear Regression</div><div class="content" id="N65796"><div class="node"><img src="Support Vector Machine.html_files/hide.png" class="hideshow" alt="hide" onClick="toggle(&quot;N65805&quot;)" id="imgN65805"/><a id="FMID_190591826FM"/><div class="nodecontent">Problems</div><div class="content" id="N65805"><div class="node"><img src="Support Vector Machine.html_files/leaf.png" class="hideshow" alt="leaf"/><a id="FMID_1243335793FM"/><div class="nodecontent">Parameters E and C must be tuned simultaneously</div></div><div class="node"><img src="Support Vector Machine.html_files/leaf.png" class="hideshow" alt="leaf"/><a id="FMID_1100362415FM"/><div class="nodecontent">Regression is intrinsically more difficult than pattern classifiication</div></div></div></div></div></div></div></div>
</body></html>